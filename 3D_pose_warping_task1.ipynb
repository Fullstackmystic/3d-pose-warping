{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3D_pose_warping_task1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCTYeJF1aHEo"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
        "\n",
        "import numpy as np\n",
        "from numpy import asarray\n",
        "import pandas as pd\n",
        "import random\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KL1bBnWWVm7"
      },
      "source": [
        "# Dataset exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feFLBN8Aenvu"
      },
      "source": [
        "\n",
        "*   Explore the **In-shop Clothes Retrieval Benchmark** of the **DeepFashion** dataset\n",
        "http://mmlab.ie.cuhk.edu.hk/projects/DeepFashion/InShopRetrieval.html\n",
        "*   Import the dataset in `Google Colab` instead of downloading the whole dataset locally\n",
        "*   Visualize some samples from the dataset\n",
        "*   Look for variations and correlations in the dataset\n",
        "*   Use the `matplotlib` and `seaborn` library to visualize data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqYTPAeKGNoG"
      },
      "source": [
        "!unzip \"/content/drive/MyDrive/img.zip\" -d \"/content/drive/MyDrive/imgdataset\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygIYik6uXXyk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22ab50c6-4359-4910-a1a0-c7c794b24b95"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95tw9lKSLqLp",
        "outputId": "e617ee38-d2dd-46cc-b89b-51089623aa03"
      },
      "source": [
        "img_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/imgdataset/img',\n",
        "    image_size=(256, 256)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 52712 files belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agb-W2P241It"
      },
      "source": [
        "plt.figure(figsize=(15, 15))\n",
        "for images,labels in img_data.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.axis(\"off\")\n",
        "  \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qdpgjYs-f6S"
      },
      "source": [
        "pip install -U seaborn-image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bkqmqm8KDsEi"
      },
      "source": [
        "import seaborn_image as isns\n",
        "isns.load_image()\n",
        "\n",
        "g = isns.ImageGrid(cells, slices=[10, 20, 30, 40])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7TM8utGWfyl"
      },
      "source": [
        "# ResNET Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76QT9itSVz99"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ws2Z2KTVUb16"
      },
      "source": [
        "\n",
        "\n",
        "*   Read about **ResNET** architecture and advantage of residual blocks\n",
        "*   Build a simple 6-layer ConvNET and train it on **CIFAR-10** dataset\n",
        "*   Introduce residual blocks in the above model and compare the results \n",
        "*   Use the `tensorflow` library to import ResNET model with imgaenet weights\n",
        "*   Change some parameters and document the results\n",
        "*   Visualize the output of some layers and add/delete layers to see the effect of individual layers on the model accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaQzCwCZmKSR"
      },
      "source": [
        "# ResNET50 Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjhZMUFC7Znm"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras import layers\n",
        "import keras.applications.resnet50\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input  \n",
        "#from keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWH4L98Dvo2Y"
      },
      "source": [
        "from tensorflow.keras import datasets\n",
        "tf.keras.datasets.cifar10.load_data()\n",
        "(x_train,y_train),(x_test,y_test) = datasets.cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Be1WjHgTkcnZ",
        "outputId": "62807e8d-8daa-44cb-92a5-958499d721c4"
      },
      "source": [
        "print(x_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBbuaohWyxXx"
      },
      "source": [
        "resnet50 = ResNet50(\n",
        "  include_top=True,\n",
        "  weights='imagenet',input_tensor=None,\n",
        "  input_shape=None,\n",
        "  classifier_activation='softmax',\n",
        ")\n",
        "\n",
        "resnet50.trainable = False\n",
        "\n",
        "resnet_model = keras.Sequential([\n",
        "    layers.UpSampling2D(size=(7, 7)),\n",
        "    resnet_base,\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax'),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZkFk3U_4Rho"
      },
      "source": [
        "resnet_model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HB-E6i1yY_hC",
        "outputId": "855ba06e-0622-4c85-bf72-bc04e27d376f"
      },
      "source": [
        "resnet_model.fit(x_train, y_train, epochs=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 197s 123ms/step - loss: 1.6632 - accuracy: 0.4118\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 195s 125ms/step - loss: 1.2029 - accuracy: 0.5755\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 195s 125ms/step - loss: 1.1076 - accuracy: 0.6123\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efa3f185550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8K964QC5rG_o",
        "outputId": "30bea03e-64f6-48f5-ed36-4f8f6a92f77d"
      },
      "source": [
        "test_loss, test_acc = resnet_model.evaluate(x_train, y_train, verbose=1) \n",
        "\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 195s 124ms/step - loss: 1.0572 - accuracy: 0.6293\n",
            "Test accuracy: 0.6292600035667419\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFIdRnXscLTt"
      },
      "source": [
        "resnet_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gohSDPMdlsQl"
      },
      "source": [
        "# Residual Blocks added"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAq-eRjAk1de"
      },
      "source": [
        "from tensorflow import Tensor\n",
        "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization, Add, AveragePooling2D, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import cifar10"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ReKKVQuk276",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64d93f11-9ac6-478b-cd50-1985af1edc20"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2ShtUQlk7rt"
      },
      "source": [
        "def relu_bn(inputs: Tensor) -> Tensor:\n",
        "    relu = ReLU()(inputs)\n",
        "    bn = BatchNormalization()(relu)\n",
        "    return bn\n",
        "\n",
        "def residual_block(x: Tensor, downsample: bool, filters: int, kernel_size: int = 3) -> Tensor:\n",
        "    y = Conv2D(kernel_size=kernel_size,\n",
        "               strides= (1 if not downsample else 2),\n",
        "               filters=filters,\n",
        "               padding=\"same\")(x)\n",
        "    y = relu_bn(y)\n",
        "    y = Conv2D(kernel_size=kernel_size,\n",
        "               strides=1,\n",
        "               filters=filters,\n",
        "               padding=\"same\")(y)\n",
        "  \n",
        "    if downsample:\n",
        "        x = Conv2D(kernel_size=1,\n",
        "                   strides=2,\n",
        "                   filters=filters,\n",
        "                   padding=\"same\")(x)\n",
        "    out = Add()([x, y])\n",
        "    out = relu_bn(out)\n",
        "    return out\n",
        "\n",
        "def create_res_net():\n",
        "    \n",
        "    inputs = Input(shape=(32, 32, 3))\n",
        "    \n",
        "    t = BatchNormalization()(inputs)\n",
        "    t = Conv2D(kernel_size=3,\n",
        "               strides=1,\n",
        "               filters=64,\n",
        "               padding=\"same\")(t)\n",
        "    t = relu_bn(t)\n",
        "    \n",
        "    num_blocks_list = [1]\n",
        "    for i in range(len(num_blocks_list)):\n",
        "        num_blocks = num_blocks_list[i]\n",
        "        for j in range(num_blocks):\n",
        "            t = residual_block(t, downsample=(j==0 and i!=0), filters=64)\n",
        "    \n",
        "    t = AveragePooling2D(4)(t)\n",
        "    t = Flatten()(t)\n",
        "    outputs = Dense(10, activation='softmax')(t)\n",
        "    \n",
        "    model = Model(inputs, outputs)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxO5d6voroV3"
      },
      "source": [
        "model = create_res_net()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLGlVOZ40YG2"
      },
      "source": [
        "model.fit(x_train, y_train, epochs=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVhfZCNyjcUq"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(x_train, y_train, verbose=1) \n",
        "\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZJwTm6E3alt"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}